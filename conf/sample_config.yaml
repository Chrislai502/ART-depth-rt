defaults:
  - _self_

# Model choices: 
#  ShuffleNet_V2_X0_5
#  MobileNet_V3_Large
#  MobileNet_V3_Small
model: 
  __target__: "art-depth.model.depth_encoder.DepthEncoder"
  initial_encoder_in_channels: 3
  initial_encoder_out_channels: 64
  initial_encoder_kernel_size: 7
  initial_encoder_stride: 2 
  initial_encoder_padding: 3
  num_enc_channels_in: [64, 64, 128, 192]
  kernel_size: 3
  stride: 2
  padding: 1
  leaky_relu_alpha: 0.1


# Training configuration
trainer:
  batch_size: 40
  learning_rate: 1e-4
  epochs: 100000
  num_workers: 8
  model_checkpoint_path: "vision_ik_model.pth"
  checkpoint_interval: 100000  # Save checkpoint frequency. Takes that much to converge anyways
  resume_checkpoint: false  # Path to checkpoint file to resume from

# Dataset configuration
dataset:
  dataset_dir: "Absolute path to dataset directory"
  save_plots: false
  stat_percentile_range: [1, 99]
  augmentations:
    apply: true
    ColorJitter:
      brightness: 0.15
      contrast: 0.2
      saturation: 0.2
      hue: 0.1
      p: 0.3
    RandomPerspective: 
      distortion_scale: 0.05
      p: 0.0
    ElasticTransform: 
      alpha: 100.0
      sigma: 7.0
      p: 0.4
    RandomResizedCrop:
      crop_scale: 0.999
      scale: [0.999, 1.0]
      ratio: [0.999, 1.01]
      p: 0.0
    JPEGCompression:
      quality_range: [80, 95]
      p: 0.5

# Neptune configuration
neptune:
  project_name: "cobot/vision-ik"
  api_token: "<Neptune API Token>"